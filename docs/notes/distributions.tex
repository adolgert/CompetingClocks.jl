\documentclass{article}
\usepackage{hyperref}
\usepackage{jlcode}
\usepackage{listings}
\usepackage{sourcecodepro}
% \usepackage[usenames,dvipsnames]{xcolor}
\usepackage[T1]{fontenc}

% \lstdefinelanguage{Julia}%
%   {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
%       end,export,false,for,function,immutable,import,importall,if,in,%
%       macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
%       using,while},%
%    sensitive=true,%
%    alsoother={$},%
%    morecomment=[l]\#,%
%    morecomment=[n]{\#=}{=\#},%
%    morestring=[s]{"}{"},%
%    morestring=[m]{'}{'},%
% }[keywords,comments,strings]%

% \lstset{language=Julia,
% 	basicstyle=\ttfamily\tiny,
% 	keywordstyle=\color{blue}\ttfamily\tiny,
% 	stringstyle=\color{red}\ttfamily\tiny,
% 	commentstyle=\color{ForestGreen}\ttfamily\tiny,
% 	morecomment=[l][\color{purple}]{\#}
% }

\title{Sampling Distributions in Julia}
\author{Andrew Dolgert}
\begin{document}
\maketitle

\section{Introduction}

In order to write a continuous-time simulation, we need to sample distributions. There are many ways to sample these distributions, and they involve different mathematical manipulations of those distributions. This document looks at the functions defined by Julia for manipulating distributions, in order to figure out how to write samplers.


\section{Notation for Distributions}
We need to use some accepted notation for a statistical distribution. Let's choose some variable names to use.

A \emph{cumulative distribution} is the probability of an event before a given time. The random variate is $T$ and $t$ is a parameter. $P$ denotes a probability, and $F$ is the name we choose for a general cumulative distribution.
\begin{equation}
  P(T \le t) = F(t)
\end{equation}
The survival is the probability an event fires after time $t$.
\begin{equation}
  P(T > t) = G(t) = 1 - F(t)
\end{equation}
The \emph{probability density function,} or pdf, is the derivative of the cumulative distribution.
\begin{equation}
  f(t) = dF(t)/dt
\end{equation}
% This distribution can combine continuous and point distributions.
% \begin{equation}
%   F(t) = F'(t) + \sum_i f_i\delta(t-t_i)
% \end{equation}
The \emph{hazard rate} is the probability per unit time of an event, given that it has not yet fired.
\begin{equation}
\lim_{\delta t\rightarrow 0} P(t < T\le t + \delta t) = \lambda(t)
\end{equation}
Every continuous distribution can be written in terms of the hazard rate.
\begin{equation}
F(t) = 1 - e^{-\int_0^t\lambda(s)ds}
\end{equation}
This means the pdf is also a function of hazard rate.
\begin{equation}
f(t) = \lambda(t)e^{-\int_0^t\lambda(s)ds}
\end{equation}
The survival, in terms of the hazard rate, is one term.
\begin{equation}
G(t)=e^{-\int_0^t\lambda(s)ds}
\end{equation}
The log of the survival is called the integrated hazard.
\begin{equation}
\ln G(t) = -\int_0^t\lambda(s)ds = -\Lambda(t)
\end{equation}

\section{Julia Distributions}
Julia has a \texttt{Distributions.jl} library that contains univariate distributions, which are what we want. Let's walk through the functions this package offers for working with those distributions. We can write each function's mathematical equivalent.

\subsection{Parameters}
Julia has one function to retrieve all parameters of a distribution and a few functions that are specific to common parameters.

\begin{itemize}
	\item \texttt{params(d::UnivariateDistribution)}---Gets all parameters for a distribution.
	\item \texttt{scale(d::UnivariateDistribution)}---If the distribution has a parameter $\theta$ and is written as $f(t/\theta)$, then $\theta$ is the scale.
	\item \texttt{rate(d::UnivariateDistribution)}---If the distribution has a parameter $\beta$ and is written as $f(\beta t)$, then $\beta$ is the rate. We see that $\beta\theta = 1$.
	\item \texttt{location(d::UnivariateDistribution)}---If the distribution has a parameter $\mu$ and is written as $f(t-\mu)$, then $\mu$ is the location. This will be important for re-sampling distributions which failed to fire.
	\item \texttt{shape(d::UnivariateDistribution)}---The shape is often a power, $k$, of $t^k$ in the pdf.
\end{itemize}

\subsection{Probability Evaluation}

\begin{table}
\begin{tabular}{lll}
	Julia Function & Equation & Statistics name \\ \hline
	\texttt{ccdf} & $S(x) = e^{-\int^x\lambda(s)ds}$ & Survival \\
	\texttt{cdf} & $F(x) = 1 - S(x) = 1-e^{-\int^x\lambda(s)ds}$ & Cumulative distribution function \\
	\texttt{pdf} & $f(x) = \lambda(x)e^{-\int^x\lambda(s)ds}$ & Probability distribution function \\
	\texttt{logpdf} & $\ln\:f(x)$ & Log-likelihood \\
	\texttt{logcdf} & $\ln\:F(x)$ & \\
	\texttt{logdiffcdf} & $\ln\left(F(x_2)-F(x_1)\right)$ & \\
	\texttt{logccdf} & $-\int^x\lambda(s)ds$ & Integrated hazard (negated) \\
	\texttt{quantile} & $y = F^{-1}(x)$ & Inverse cumulative distribution function \\
	\texttt{cquantile} & $y = F^{-1}(1-x)$ so $x = S(y)$ & Inverse Survival \\
	\texttt{invlogcdf} & $x = \ln\:F(y)$ so $e^x = F(y)$ & \\
	\texttt{invlogccdf} & $x = -\int_0^y\lambda(s)ds$ & Inverse integrated hazard
\end{tabular}
\caption{This translates between Julia functions and hazard-based notation. We can use this to find
the shortest path to our calculation in code.\label{julia-translation}}
\end{table}

\texttt{insupport(d::UnivariateDistribution, x::Any)}---Whether $t$ is in the domain of $f(t)$.

\texttt{pdf(d::UnivariateDistribution, x::Real)}---This is $f(t)$.

\texttt{logpdf(d::UnivariateDistribution, x::Real)}---It's $\ln(f(t))$. This is important because the pdf is a likelihood, so you get the log-likelihood.

\texttt{cdf(d::UnivariateDistribution, x::Real)}---$F(t)$.

\texttt{logcdf(d::UnivariateDistribution, x::Real)}---$\ln(F(t))$.

\texttt{logdiffcdf(d::UnivariateDistribution, x::Real, y::Real)}---$\ln(F(x))-\ln(F(y))$.

\texttt{ccdf(d::UnivariateDistribution, x::Real)}---Survival, $G(t) = 1-F(t)$.

\texttt{logccdf(d::UnivariateDistribution, x::Real)}---The log of the survival, which is called the integrated hazard, $\Lambda(t)$.

\texttt{invlogcdf(d::UnivariateDistribution, x::Real)}---The inverse function of log-CDF. That's
\begin{equation}
x = \ln F(y)
\end{equation}
so
\begin{equation}
e^x = F(y) = 1 - e^{\int_0^y\lambda(s)ds}.
\end{equation}

\texttt{invlogccdf(d::UnivariateDistribution, x::Real)}---This inverse is one I've used.
\begin{equation}
e^x = G(y) = e^{\int_0^y\lambda(s)ds}
\end{equation}
That means this function is the inverse of the integrated hazard.
\begin{equation}
x = \Lambda(y)
\end{equation}


\section{Next Reaction for Non-Markov Processes}

Gibson and Bruck describe the Next Reaction Method for non-Markov processes by focusing on one step of the algorithm. Identify the transitions with $a$ and the time points as $T_n$. Assuming there was a draw for some time $\tau$ when the distribution $F_{a,n}$ would fire, and there is now a change to create distribution $F_{a,n+1}$, the new draw should be
\begin{equation}
	\tau'=F_{a,n+1}^{-1}\left(\frac{F_{a,n}(\tau) - F_{a,n}(t_n)}{1-F_{a,n}(t_n)}\right).
\end{equation}
Shifting to get rid of the inverse, this becomes
\begin{equation}
	F_{a,n+1}(\tau')=\frac{F_{a,n}(\tau) - F_{a,n}(t_n)}{1-F_{a,n}(t_n)}.
\end{equation}
I suspect this equation will make a lot of sense if we write it in terms of survivals. Start by writing it as $S=1-F$
\begin{equation}
	1-F_{a,n+1}(\tau')=\frac{1-F_{a,n}(\tau)}{1-F_{a,n}(t_n)}.
\end{equation}
Multiplying both sides by the denonminator shows a known rule about survival functions. The rule is that \emph{conditional survival is multiplicative.}
\begin{equation}
	\left(1-F_{a,n}(t_n)\right)\left(1-F_{a,n+1}(\tau')\right)=1-F_{a,n}(\tau).\label{eqn:survivalrule}
\end{equation}
The equation says that we expect the proposed survival of this process to time $\tau$ to be the same as the survival to from start to $t_n$ and the survival from $t_n$ to $\tau'$.

Have you been anxious about the notation? The Gibson and Bruck paper failed with the notation, and we just copied it. The problem is how they annotated the zero-time for distributions. We can clarify it by writing the equation in terms of hazards.
\begin{equation}
	\exp\left(-\int_{t_0}^{\tau}\lambda_n(s)ds\right) = \exp\left(-\int_{t_0}^{t_n}\lambda_n(s)ds\right)\exp\left(-\int_{t_n}^{\tau'}\lambda_{n+1}(s)ds\right)
\end{equation}
The integrals cover the relevant durations and the hazards are the hazards of those distributions during those durations. This equation also leads to an observation. Anderson's method is the Next Reaction method in log space. Who knew? Everybody. Everybody knew.

We can make our notation in a way that will have an echo in the code. All software libraries treat distributions as starting at time zero and leave it to the client to shift their absolute time. Therefore, let's think about distributions as an enabling time that defines the zero, a current time, and the distribution, $(t_e, t_n, f)$.

If we think of the first draw as a draw by inversion, we can write it as inversion of a conditional survival.
\begin{equation}
	U = S(t_n - t_e, \tau - t_n)
\end{equation}
Because $0<U<1$, this could equally well be $U=F(t_n-t_e, \tau-t_n)$ equally well. If the enabling time is in the future, that's fine, but it changes the draw to use a marginal survival.
\begin{equation}
	U = S(0, \tau - t_e) = S(\tau - t_e)
\end{equation}
This $U$ is the right-hand side of \ref{eqn:survivalrule}.

When Gibson and Bruck discuss an update rule, it requires storing the remaining $U$.
\begin{enumerate}
	\item When we make the first draw, we save $U$.
	\item Each time, $t_n$, a transition is disabled, we calculate
		\begin{equation}
			U'=\frac{U}{S(t_n-t_e, \tau - t_n)}
		\end{equation}
	\item When the transition is enabled or changed, we calculate its draw by inversion with the saved $U'$,
	\begin{equation}
		U'=S(t_n-t_e, \tau' - t_n).
	\end{equation}
\end{enumerate}
While the first draw of $\tau$ can be done using appropriate, non-inversion, methods for any distribution, it is a weakness of this method that later enabling of the transition requires using inversion, which can be much slower and more error-prone.

Let's walk through the cases because they clarify what we need to store within the sampler.
\begin{itemize}
	\item First time enabling the transition. Sample any way possible from $S(t_n-t_e, \tau-t_n)$, but then calculate and store $U=S(t_n-t_e, \tau-t_n)$.
	\item Enabling a transition that fired. Sample any way possible from $S(t_n-t_e, \tau-t_n)$, but then calculate and store $U=S(t_n-t_e, \tau-t_n)$.
	\item Enabling a transition that was disabled before it fired.
	\begin{itemize}
		\item General case. Sample by inversion $U=S(t_n-t_e, \tau-t_n)$.
		\item The transition is picking up where it left off. We don't have to sample because the firing time is just pushed forward. Does this happen often enough to care? If the previous distribution was $(t_e, t_n, f)$ when it was disabled at time $t_n$, we know the transition is merely shifted because, at time $t_{n+1}$, it has the form $(t_{n+1}-(t_e-t_n), t_{n+1}, f)$. In this case, $\tau' = \tau + t_{n+1}-t_n$, and there is no change to the stored $U$.
	\end{itemize}
	\item Disabling a transition that did not fire. If a transition did not fire at time $t_{n+1}$, calculate conditional survival, $S(t_n-t_e, t_{n+1}-t_e)$ and adjust the stored $U$ by dividing by the conditional survival.
	\item Disabling the transition that fired. If we adjust the conditional survival according to the formula above, it may close to zero but not equal. We need it to be $U=0$, so set that value.
\end{itemize}
From the cases above, the sampler needs to store two kinds of information.
\begin{itemize}
	\item Long-term values about all transitions. These are $U$, $t_e-t_n$, and $f$.
	\item Short-term values for currently-enabled transitions. These are $t_e$, $t_n$, $f$.
\end{itemize}

There are a couple of challenges. One is how to know when two floating-point values are equal, such as in the check that the transition is picking up where it left off. This is handled in code by calculating the machine epsilon for a floating point of the size of $t_n$. Multiply that by a small factor, such as 2 or 4, and use that as an error bound.

Another challenge is how to figure out which disabled transition is the one that fired. If the caller specifies it is disabling the transition that fired, then it's clear. If the caller doesn't specify, can we know? The transitions are in a heap where the soonest is on top. If the first transition that's disabled was the one on top and the next transition becomes the one on top, it could look like it was next to fire. We could check the times on those transitions in order to see whether the time of disabling matches the time of the top transition, but that's prone to error because it requires equality of floating-point numbers. There will definitely be some time when two numbers in a continuous time simulation are very close to each other.

On the other hand, there isn't a good way to use a Next Reaction sampler except to always choose the transition it sampled to be next. Let's store the response from the next() function and assume that's the one that fired when it gets disabled.

\section{Timing Sampling Methods}

The Next Reaction method (Gibson and Bruck) and the Modified Next Reaction method (Anderson) are essentially the same algorithm except that one samples in a linear space and one samples in a logarithmic space. Which one is better depends on the distribution we're sampling and the parameter ranges for that distribution. This section looks at tests of the distributions defined in Julia in order to classify which one goes in which category, linear or logarithmic sampling.

Below is a table that comes from a test in \texttt{test/nrmetric.jl}. The distributions come from \texttt{Distributions.jl}. Each distribution appears twice, once with default parameters and once as a truncated distribution, which is Julia's way of limiting the distribution's support so that we can sample values that are later than a given time. Each distribution is tested on 10,000 values. The table will have the following values.

\begin{enumerate}
	\item The space for the test, which is linear or logarithmic.

	\item Error, as the log base-10 of the maximum error after sampling a survival and then inverting that back to get the sample. When the number is -16, that means the error is $10^{-16}$.

	\item Average error in log base-10, which is the trimmed mean over all runs of the error in the previous column.

	\item Forward timing in seconds. For the linear space, this is the time to perform the \texttt{ccdf} call. For the logarithmic space, this is the time to perform the \texttt{logccdf} call, both 10,000 times. A time of 6e-4 seconds means each iteration took, on average, 6e-8 seconds.

	\item Backward timing in seconds. For the linear space, this is the time to perform the \texttt{cquantile} call. For the logarithmic space, this is the time to perform the \texttt{invlogccdf} call, both 10,000 times.
\end{enumerate}

\pagebreak
\input{snippet1}

\pagebreak
\input{snippet2}

\pagebreak
\input{snippet3}

The tables highlight which sampling method is more accurate and which is faster. Sometimes these two are at odds. Here's how I made choices.

\begin{itemize}
	\item Some distributions have trouble with log-space sampling in the tails. The Gumbel distribution is a good example. It works fine for values in between -2 and 2, but linear sampling remains stable outside that region, so we take the safer bet.

	\item If the accuracy is great for either choice, but one is much faster, let's go with the faster one. The Laplace distribution is a good example. The worst accuracy is $10^{-15}$, but the log-space sampling is ten times faster. Another example is Cosine, where the log-space sampling gets an accuracy of $10^{-5.4}$ but the linear-space sampling accuracy is $10^{-10.9}$. While log-space is faster, we should surely use the linear sampling.
\end{itemize}

The Laplace distribution is the only one I can see going either way. You can either get ten times the accuracy or ten times the speed.

The Exponential distribution has a problem with truncation. This should be fast and accurate but fails on both counts.


\section{Competing Processes}

In this section, we ask how to calculate the likelihood of a trajectory. A trajectory is a single element of the joint random variables $\left\{X_n,T_n\right\}$ where $X_n$ is the state at time $n$ and $T_n$ is the time at time $n$. The curly-braces denote the set of all times $n$. Our goal is to be able to calculate this quantity numerically using a simulation.

Start by asking the cumulative distribution function of a single step of a trajectory. Think of distributions, defined relative to a start time at $T_n$. Each is set to fire at some next time $x_a$. The joint cumulative density function from one time $T_n$ to the next, $T_{n+1}$ can be decomposed into independent density functions.
\begin{eqnarray}
	F_n(x_1, x_2,\ldots,x_m) &= &\int_0^{x_1}\cdots\int_0^{x_m}f(\xi_1,\xi_2,\ldots,\xi_m)d\xi_m\ldots d\xi_1 \\
	&= &\int_0^{x_1}\cdots\int_0^{x_m}\prod_a f_a(\xi_a)d\xi_m\ldots d\xi_1\ \\
	&= &\prod_a \left[\int_0^{\xi_a}f_a(\xi_a)d\xi_m\ldots d\xi_1\right]
\end{eqnarray}
If the next time step is at time $t=T_{n+1}-T_n$, then the joint cumulative distribution function is $F_n(t)=\prod_a F_a(t).$

Now that we have the cumulative distribution function, it may be easier to see the likelihood of a single step of the trajectory. Given competing processes, the likelihood is the probability that one particular trajectory, called $\alpha$, fires between time $t$ and $t+\delta t$, and all other transitions fire later. We'll use $S(t)$ for the survival and $h(t)$ for the hazard.
\begin{eqnarray}
	c_{\alpha}(t)dt &=& f_{\alpha}(t)\prod_{a\ne\alpha}\left[\int_{t}^\infty f_a(\xi_a)dx_a\right] \\
	&=& f_{\alpha}(t)\prod_{a\ne\alpha}S_a(t) \\
	&=& \frac{f_{\alpha}(t)}{S_\alpha(t)}\prod_{a}S_a(t) \\
	&=& h_{\alpha}(t)\prod_{a}S_a(t)
\end{eqnarray}
At time $T_n$, there is a continuous likelihood $c_\alpha(t)$ for each $\alpha\in a$. If we think about the sequence of $\left\{T_n\right\}$, the $c_\alpha(t)$ form a matrix called the core matrix.

We can translate the log-likelihood into Julia code. The first step is to express competing processes as long-lived competing processes. Account for the enabling times and for distributions that were enabled at a previous transition. Then rewrite this equation in terms of Julia functions.

Look, these values are remarkably similar to those computed for the Next Reaction method. And here's how they relate to Gillespie's method.


\section{Common random numbers}

Instead of calling \texttt{rand(rng, distribution)}, change it to \texttt{rand(rng, distribution, clock)}. Then keep track of a) the clock b) its $n$-th call and c) the survival associated with that call. Record choices and replay.

This works best with samplers that use fewer random numbers, such as the Next Reaction method. It's these lines we would want to replace. In the case of CRN, the input wouldn't be a random sample but would be a survival from which to determine the sample.

\begin{jllisting}
sample = rand(rng, distribution)
tau = te + sample
survival = survival_space(S, distribution, sample)
\end{jllisting}

What if you used CRN and a direct method? I don't know.


\section{Importance Sampling}

Why would you calculate a likelihood? So that you can artificially increase the likelihood of trajectories with desired outcomes in order to improve their statistics.

\subsection{Splitting}

This version of importance sampling is simple to implement. When a trajectory is in the right direction, split it into multiple trajectories. Then, when counting results, down-weight those trajectories by the split. If one trajectory splits into 10, count the results by 1/10th.

A good example of splitting is a simulation that takes place on an energy landscape. Picture two valleys and a mountain pass between them. The simulation starts in one valley and rarely crosses the pass to the next valley. For those simulations that approach the pass, you could split the trajectories in order to increase the quality of statistics for the likelihood of reaching the other valley.

Splitting is implemented not in the sampler but in the driver of the simulation. You would copy the simulation state and the sampler state $N$ times and then down-weight the contribution of each.

How would we implement that?


\subsection{Exclusion}

Here, we choose a transition and disallow it from firing. For instance, it's common in disease modeling to ask how large an outbreak would be, were there an outbreak. That's a conditional probability, conditioned on the disease never reaching extinction. 

There are two ways to calculate an exclusion-sampled trajectory. Picture a herd of animals with only one infectious. It could either recover or infect another in the herd, and we'll exclude recovery, but we have to account for the decreased likelihood of the trajectory given that it excludes recovery.

One approach is to calculate the marginal probability of recovery and discount the ensuing draw. This works for sure.

The other approach is to leave recovery in the draws and use the draws themselves to do the downweighting. (Maybe?)


\subsection{Weighting Probability}

This is the most difficult version to do. You have to take the core matrix, aka the XXX. Then adjust each $c_\alpha(t)$ with a multiplicative weight. Then reconstitute the total survival, taking the hazard from the reweighted core matrix. Now draw from this distribution.


\subsection{Examples}
Example: Preventing extinction in disease simulation.

Example: Estimation of energy barrier.


\section{Hamiltonian Monte Carlo}

My favorite housing spread example.


\section{Piecewise Deterministic Markov Processes}

As long as the sampler can sample the distribution using the given methods, that distribution can be determined by any equation, including an ODE. In one version, the distribution is a delta function, and these completely work. You have to re-enable the distribution each time the ODE changes its prediction. In another version, there is still a continuous distribution, but it's determined by the ODE.

Show that a delta-function can be included in Fleck.

\end{document}
